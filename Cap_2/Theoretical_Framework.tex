\chapter{Theoretical Framework}
\label{ch:theoretical_framework}

The development of the MONEEE system is grounded in the convergence of neurophysiological principles, precision electronic engineering, and computer science. This section systematizes the critical concepts required for the device's implementation, addressing the stochastic nature of biological signals, the low-noise acquisition architecture, and the challenges inherent to temporal synchronization in heterogeneous digital systems.

\section{Neurophysiology and Event-Related Potentials (ERPs)}
\label{sec:neurophysiology}

Electroencephalography (EEG) constitutes a non-invasive technique for recording cerebral bioelectric activity via transducers arranged on the scalp. While continuous EEG analysis allows for the monitoring of basal brain states—such as wakefulness, sleep, or convulsive pathologies—cognitive neuroscience research requires isolating specific neuronal responses associated with sensory, motor, or cognitive stimuli. These voltage fluctuations, known as Event-Related Potentials (ERPs), represent the synchronized activity of pyramidal neuronal populations in response to information processing.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Cap_2/Figure/p300_waveform.png}
    \caption{Characteristic morphology of an Event-Related Potential (ERP), highlighting exogenous and endogenous components such as the N200 and P300.}
    \label{fig:p300_waveform}
\end{figure}

Within the complex morphology of ERPs, two endogenous components are of particular interest for neurocognitive evaluation and the implementation of serious games in the context of this project. The first is the N200 (or N2) component, a negative deflection that reaches its maximum amplitude between 200 and 350 ms post-stimulus. This component is functionally linked to executive control, specifically in mismatch detection processes and the inhibition of motor responses. The second component, the P300 (or P3b), manifests as a prominent positive deflection with a latency of 300 to 600 ms. Its amplitude is modulated by the allocation of attentional resources and the updating of working memory, being particularly sensitive to stimulus improbability (the \textit{oddball} paradigm). Due to these characteristics, the P300 is consolidated as a robust biomarker for quantifying cognitive load and attentional deficits.

The detection of these components presents a significant challenge in signal processing due to their low signal-to-noise ratio (SNR). ERPs possess typical amplitudes in the range of $1\mu V$ to $20\mu V$, frequently remaining masked by background EEG activity, the magnitude of which oscillates between $50\mu V$ and $100\mu V$. To extract the signal of interest, the technique of coherent signal averaging is employed. Assuming that background noise is a stochastic process with zero mean and is uncorrelated with the stimulus, by averaging $N$ trials, the noise amplitude decreases in proportion to $1/\sqrt{N}$, while the ERP signal remains constant.

However, the validity of this technique depends strictly on temporal stability. Variability in the synchronization marker's latency, a phenomenon termed \textit{jitter}, introduces systematic errors in the resulting average. Mathematically, if the trigger latency follows a normal distribution with standard deviation $\sigma_t$, the averaging process acts as a low-pass filter on the original waveform, attenuating high-frequency components and distorting peak amplitude. A jitter greater than 10 ms ($\sigma_t > 10$ ms) is sufficient to degrade the morphology of the N200 component, compromising the diagnostic utility of the data. Consequently, the MONEEE system must guarantee strict real-time (\textit{hard real-time}) synchronization to preserve the spectral and temporal integrity of the biomarkers.

\section{Hardware Architecture for Signal Acquisition}
\label{sec:hardware}

The fidelity in the digitization of biopotentials is determined by the topology of the Analog Front-End (AFE). The proposed system integrates the Texas Instruments ADS1299 integrated circuit, an analog-to-digital converter (ADC) designed specifically for biomedical instrumentation, which implements a Delta-Sigma ($\Delta\Sigma$) modulation architecture.

Unlike the Successive Approximation Register (SAR) converters common in general-purpose microcontrollers, the $\Delta\Sigma$ architecture offers superior advantages in terms of dynamic range and noise rejection through two main mechanisms: oversampling and noise shaping. The device samples the input signal at a modulation frequency ($f_{mod}$) significantly higher than the Nyquist rate, distributing quantization noise power over a wider spectrum. Subsequently, the modulator shifts this noise toward high frequencies, outside the biological band of interest (0--100 Hz), allowing a digital decimation filter to eliminate it effectively while reducing the data rate to the output frequency configured by the user.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Cap_2/Figure/delta_sigma_block.png}
    \caption{Simplified functional scheme of the modulation and filtering stage in a Delta-Sigma architecture ADC.}
    \label{fig:delta_sigma}
\end{figure}

A critical aspect for functional connectivity and EEG coherence analysis is sampling simultaneity. In traditional multiplexed systems, a single ADC core switches sequentially between channels, introducing a systematic phase delay ($t_{skew}$) between electrodes. The ADS1299 mitigates this problem by incorporating independent $\Delta\Sigma$ modulators for each of its 8 channels, guaranteeing a virtually null $t_{skew}$ and preserving the real phase relationship between different cortical regions.

To manage data flow without sacrificing temporal determinism, the MONEEE system design adopts a heterogeneous computing architecture that decouples acquisition from high-level processing. This structure is composed of a Microcontroller Unit (MCU), such as the TM4C1294, and a Microprocessor Unit (MPU), based on embedded Linux. The MCU operates under real-time constraints (either on \textit{bare-metal} or with a lightweight RTOS), reacting to ADC hardware interrupts (\texttt{DRDY}) on microsecond scales to capture and timestamp samples, preventing FIFO buffer overflows. Meanwhile, the MPU manages computationally intensive and non-deterministic tasks, such as the TCP/IP protocol stack and file system storage. This division of responsibilities isolates bio-signal acquisition from the variable latencies introduced by the Linux kernel scheduler, ensuring data temporal integrity.

\section{Digital Synchronization Protocols}
\label{sec:sync_protocols}

Precise synchronization between the physiological recording and events generated by the stimulation software (video game) constitutes the central technical challenge of this research. The selection of the synchronization method implies a trade-off between temporal precision, implementation complexity, and intrusion into the user experience. Table \ref{tab:sync_methods} summarizes the characteristics of the predominant approaches.

\begin{table}[ht]
    \centering
    \caption{Comparative analysis of synchronization methods for BCI systems.}
    \label{tab:sync_methods}
    \begin{tabular}{p{3cm} p{5cm} p{2.5cm} p{3.5cm}}
        \toprule
        \textbf{Method} & \textbf{Mechanism} & \textbf{Precision} & \textbf{Implementation} \\
        \midrule
        Optical (Photodiode) & Physical detection of screen luminance changes by an external sensor. & High ($<1$ ms) & High (Additional hardware required). \\
        Network (LSL) & Synchronization via local network protocol and software jitter correction. & Medium ($<5$ ms) & Low (Software only). \\
        Hardware Trigger (TTL) & Direct electrical signal from Parallel/USB port to the ADC. & Very High ($<1$ ms) & Medium (Requires specific interfaces). \\
        \bottomrule
    \end{tabular}
\end{table}

There are contrasting approaches to addressing this problem. Optical synchronization, based on photodiodes attached to the monitor, is considered the ``gold standard'' for validation, as it detects the physical change of pixels, bypassing software, operating system, and GPU rendering latencies. However, its requirement for external hardware limits its viability in massive clinical deployments. As a scalable alternative, the \textit{Lab Streaming Layer} (LSL) protocol offers a middleware solution that unifies disparate data streams by assigning timestamps referenced to a common clock and drift correction algorithms. While LSL simplifies integration, its final accuracy remains dependent on local network stability and the game engine's ability to report the event time accurately.

In the context of the MONEEE system's physical interface, the USB bus introduces non-trivial latency considerations, especially for the transmission of marking commands (\textit{soft-triggers}) from the PC to the amplifier. As a host-controlled bus utilizing polling, data transfer is discretized into frame intervals (1 ms in \textit{Full Speed}) or microframes ($125 \mu s$ in \textit{High Speed}). Additionally, the use of the CDC (\textit{Communication Device Class}) to emulate serial ports implies that data traverses the operating system driver stack, where it may be stored in intermediate buffers to optimize global system performance. This behavior introduces variable and unpredictable latencies of several milliseconds between the logical generation of the event in the game and its physical arrival at the USB bus, which is incompatible with the precision requirements for high-frequency ERP component analysis.

To address the latency indeterminacy introduced by the USB stack and OS buffering, the MONEEE system implements a \textit{hardware-embedded synchronization protocol} that couples synchronization logic directly to the biological sample at the firmware level. Unlike architectures that transmit event markers and EEG data through separate logical channels, MONEEE adopts a specific hexadecimal frame structure where the initial three bytes are strictly reserved for control data, thereby eliminating the need for post-hoc timestamp realignment.

In this encoding scheme, the first byte acts as a binary Event Flag ($B_{0}$), explicitly indicating the presence of a synchronization trigger with a value of \texttt{1} or a resting state with \texttt{0}, while the second byte ($B_{1}$) designates the Event Type, carrying the specific code required to classify the nature of the stimulus (e.g., distinguishing between target and standard inputs). This metadata is immediately followed by the third byte ($B_{2}$), which serves as a static Start-of-Frame delimiter to identify the beginning of the physiological data payload. By packaging the event markers and the EEG signal within this same atomic transmission unit, the system transforms the synchronization problem into a data parsing task, ensuring that the relative phase relationship is preserved regardless of the jitter introduced by the USB communication or the operating system scheduler.

% --- Place this immediately after the text about the frame structure ---

