\chapter{Aims}

\section{Aims}\label{sec:objectives}

%----------------------------------------------------------------------
\subsection{General Aim}
%that integrates customized activation and loss functions to improve noise robustness
%Develop a NLP optimization model based on physics-informed neural networks , that allows addressing the non linear function(pressure& flow)specific challenges  of gas-powered energy systems in Colombia and model the behavior of flows and pressures meeting nonlinear system restrictions.


%Falta mencionar la forma como se cuantifica la convergencia y tiempo en problemas no lineales

Propose a hybrid model for the EQA task, which alternates between the large pre-trained language models Roberta \cite{liu2019roberta} and Distilbert \cite{sanh2019distilbert} according to the semantic class, in order to improve the performance of the RawAtt \cite{abnar2020quantifying} interpretability technique on the VisualMRC database \cite{tanaka2021visualmrc}.

%----------------------------------------------------------------------
\subsection{Specific Aims}

    \begin{itemize}


         \item Compare the performance of RawAtt \cite{abnar2020quantifying}, Rollout \cite{abnar2020quantifying} and AttCat \cite{qiang2022attcat} interpretability techniques on large pre-trained language models such as BERT \cite{devlin2018bert}, Roberta \cite{liu2019roberta} and Distilbert \cite{sanh2019distilbert} on the VisualMRC database \cite{tanaka2021visualmrc}.

        \item Among the interpretability techniques and large pre-trained language models mentioned in the previous objective, find the interpretability technique and large pre-trained language model that together offer the best performance in terms of interpretability for each of the semantic classes in the which the VisualMRC database \cite{tanaka2021visualmrc} is typed.

        \item Make the proposed hybrid model more robust than the individual models tested to changes in text types.

    \end{itemize}