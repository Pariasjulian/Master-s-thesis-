\chapter{Final Remarks}
\label{ch:chapter_5}


%======================================================================
\section{Conclusions}

In this research, we have addressed the crucial challenge of interpretability in question answering systems, especially in transformer-based architectures. Through the exhaustive evaluation of interpretability techniques and LLMs based on transformer architectures on the VisualMRC \cite{tanaka2021visualmrc} database, we have been able to propose a hybrid model that effectively combines the strengths of multiple LLMs and the RawAtt interpretability technique, demonstrating significant improvements in interpretability and robustness with respect to individual models.

On the other hand, our research provides a detailed comparison of RawAtt \cite{abnar2020quantifying}, AttCat \cite{qiang2022attcat} and Rollout \cite{abnar2020quantifying} interpretability techniques on transformer architectures such as BERT \cite{devlin2018bert}, Roberta \cite{liu2019roberta} and Distilbert \cite{sanh2019distilbert} on the VisualMRC database \cite{tanaka2021visualmrc}. The results reveal that RawAtt \cite{abnar2020quantifying} stands out as the most effective technique to improve interpretability in the EQA task on the VisualMRC database \cite{tanaka2021visualmrc}, offering a clearer understanding of the decision-making process in all the evaluated semantic classes of the VisualMRC database \cite{tanaka2021visualmrc}.

This research represents a significant advance in the understanding of how transformer architectures work internally in the EQA task, highlighting the importance of interpretability to improve confidence in the results and facilitate future research in this field.

\newpage


\section{Future Work}

To advance our research and build upon our current findings, we have identified
several directions for future work. The following are the next possible continuing paths we envision:

\begin{itemize}
    \item develop and implement a chatbot for the National University of Colombia - Manizales Campus. This will involve integrating the proposed hybrid model, as well as the identified interpretability techniques, into the question answering system. Extensive testing will be essential to ensure that the chatbot provides accurate and useful answers to university documentation queries.
    
    \item Improving the performance of transformer architectures in question answering (QA), machine reading comprehension (MRC), visual question answering (VQA) and visual machine reading comprehension (VMRC) tasks.

    \item Development new interpretability techniques at the token relevance level for transformer architecture in multiples NLP tasks.
    \end{itemize}